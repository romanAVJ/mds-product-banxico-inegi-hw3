{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELT Banxico & INEGI data to build Athena's database\n",
    "\n",
    "Using the `fx`, `tiie` and `inpc`, create a database in Athena to analyze the behavior of the Mexican economy.\n",
    "\n",
    "@roman avj\n",
    "\n",
    "18 mar 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from pyathena import connect\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# get config file\n",
    "with open('../config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Settings\n",
    "session = boto3.Session(profile_name=\"arquitectura\")\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# set region east-1 to boto3\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "# Bucket\n",
    "BUCKET_NAME = config['aws']['bucket']\n",
    "\n",
    "# Sub Bucket\n",
    "SUB_BUCKET = config['aws']['sub-bucket']\n",
    "\n",
    "# Bucket Query\n",
    "BUCKET_QUERY = config['aws']['bucket_queries']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Configure Database at Athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create glue client with profile session\n",
    "glue_client = session.client('glue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '091cb7a9-465d-4b04-aaaa-a5f6fc43e2d2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 21 Mar 2024 14:40:16 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': '091cb7a9-465d-4b04-aaaa-a5f6fc43e2d2'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Create Database\n",
    "# create database\n",
    "response = glue_client.create_database(\n",
    "    DatabaseInput={\n",
    "        'Name': config['aws']['database'],\n",
    "        'Description': 'Database for the banxico-inegi Database'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'FD2B1Q0F95N8N2D9', 'HostId': 'VP5VjlBzsGi661B4KBlQq+O7OpsDwqoKjGiv3NTbRjNOdQ68OSc+x2k7WOILYOvLacAlmLTSW86MguJ2CQMEFA==', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'VP5VjlBzsGi661B4KBlQq+O7OpsDwqoKjGiv3NTbRjNOdQ68OSc+x2k7WOILYOvLacAlmLTSW86MguJ2CQMEFA==', 'x-amz-request-id': 'FD2B1Q0F95N8N2D9', 'date': 'Thu, 21 Mar 2024 14:17:52 GMT', 'location': '/itam-analytics-roman-queries', 'server': 'AmazonS3', 'content-length': '0'}, 'RetryAttempts': 0}, 'Location': '/itam-analytics-roman-queries'}\n"
     ]
    }
   ],
   "source": [
    "# Create Query Bucket\n",
    "response = s3.create_bucket(Bucket=BUCKET_QUERY)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Athena Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# read files from s3\n",
    "def read_from_s3(folder, filename, s3_session):\n",
    "    # remove .csv from filename\n",
    "    filename_path = filename.replace('.csv', '')\n",
    "\n",
    "    df = wr.s3.read_csv(\n",
    "        path=f\"s3://{BUCKET_NAME}/{SUB_BUCKET}/{folder}/{filename_path}/{filename}\",\n",
    "        boto3_session=s3_session\n",
    "    )\n",
    "    # set date as datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# read files from s3\n",
    "dict_df = {}\n",
    "for key, value in tqdm(config['aws']['filenames'].items()):\n",
    "    dict_df[key] = read_from_s3('raw', filename=value, s3_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe: inpc\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75 entries, 0 to 74\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    75 non-null     datetime64[ns]\n",
      " 1   inpc    74 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 1.3 KB\n",
      "None\n",
      "\n",
      "Dataframe: dollar_fx\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1623 entries, 0 to 1622\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   date       1623 non-null   datetime64[ns]\n",
      " 1   dollar_fx  1623 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 25.5 KB\n",
      "None\n",
      "\n",
      "Dataframe: tiie\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1623 entries, 0 to 1622\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    1623 non-null   datetime64[ns]\n",
      " 1   tiie    1623 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 25.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# look dataframes\n",
    "for key, value in dict_df.items():\n",
    "    print(f\"\\nDataframe: {key}\")\n",
    "    print(value.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tables\n",
    "def create_external_table_athena(df, database_name, table_name, s3_location, boto3_session):\n",
    "    # Body Query\n",
    "    query = \"\"\"\n",
    "        CREATE EXTERNAL TABLE IF NOT EXISTS `{database_name}`.`{table_name}` ({columns})\n",
    "        COMMENT \"{comment}\"\n",
    "        ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
    "        WITH SERDEPROPERTIES ('field.delim' = ',')\n",
    "        STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "        LOCATION {s3_location}\n",
    "        TBLPROPERTIES ('classification' = 'csv', \"skip.header.line.count\"=\"1\")\n",
    "    \"\"\"\n",
    "\n",
    "    # get columns\n",
    "    dict_dtype_map = {'datetime64[ns]': 'DATE', 'int64': 'INT', 'float64': 'FLOAT', 'object': 'STRING'}\n",
    "\n",
    "    # create columns\n",
    "    columns = []\n",
    "    for column, dtype in df.dtypes.items():\n",
    "        columns.append(f\"{column} {dict_dtype_map.get(str(dtype), 'STRING')}\")\n",
    "    columns_str = ',\\n'.join(columns)\n",
    "\n",
    "    # create comment\n",
    "    comment_str = f\"Table for the {table_name} dataset\"\n",
    "\n",
    "    # create query\n",
    "    query = query.format(\n",
    "        database_name=database_name,\n",
    "        table_name=table_name,\n",
    "        columns=columns_str,\n",
    "        comment=comment_str,\n",
    "        s3_location=f\"'s3://{BUCKET_NAME}/{s3_location}'\"\n",
    "    )\n",
    "    print(query)\n",
    "\n",
    "    # execute query\n",
    "    response = wr.athena.read_sql_query(\n",
    "        sql=query,\n",
    "        database=database_name,\n",
    "        ctas_approach=False, \n",
    "        boto3_session=boto3_session\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating table for: inflacion ====================\n",
      "\n",
      "        CREATE EXTERNAL TABLE IF NOT EXISTS `econ`.`inflacion` (date DATE,\n",
      "inpc FLOAT)\n",
      "        COMMENT \"Table for the inflacion dataset\"\n",
      "        ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
      "        WITH SERDEPROPERTIES ('field.delim' = ',')\n",
      "        STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "        LOCATION 's3://itam-analytics-roman/homeworks/banxico-inegi/raw/inflacion/'\n",
      "        TBLPROPERTIES ('classification' = 'csv', \"skip.header.line.count\"=\"1\")\n",
      "    \n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Creating table for: tipo_de_cambio ====================\n",
      "\n",
      "        CREATE EXTERNAL TABLE IF NOT EXISTS `econ`.`tipo_de_cambio` (date DATE,\n",
      "dollar_fx FLOAT)\n",
      "        COMMENT \"Table for the tipo_de_cambio dataset\"\n",
      "        ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
      "        WITH SERDEPROPERTIES ('field.delim' = ',')\n",
      "        STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "        LOCATION 's3://itam-analytics-roman/homeworks/banxico-inegi/raw/tipo_de_cambio/'\n",
      "        TBLPROPERTIES ('classification' = 'csv', \"skip.header.line.count\"=\"1\")\n",
      "    \n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Creating table for: tasa_de_interes ====================\n",
      "\n",
      "        CREATE EXTERNAL TABLE IF NOT EXISTS `econ`.`tasa_de_interes` (date DATE,\n",
      "tiie FLOAT)\n",
      "        COMMENT \"Table for the tasa_de_interes dataset\"\n",
      "        ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
      "        WITH SERDEPROPERTIES ('field.delim' = ',')\n",
      "        STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "        LOCATION 's3://itam-analytics-roman/homeworks/banxico-inegi/raw/tasa_de_interes/'\n",
      "        TBLPROPERTIES ('classification' = 'csv', \"skip.header.line.count\"=\"1\")\n",
      "    \n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# create tables\n",
    "for key, value in dict_df.items():\n",
    "    # get filename_key\n",
    "    filename_key = config['aws']['filenames'][key].replace('.csv', '')\n",
    "\n",
    "    print(f\"\\nCreating table for: {filename_key} {'='*20}\")\n",
    "    # create table\n",
    "    response = create_external_table_athena(\n",
    "        df=value,\n",
    "        database_name=config['aws']['database'],\n",
    "        table_name=filename_key,\n",
    "        s3_location=f\"{SUB_BUCKET}/raw/{filename_key}/\",\n",
    "        boto3_session=session\n",
    "    )\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Extract & Load & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE econ.banxico_inegi AS (\n",
      "WITH monthly_fx AS (\n",
      "    SELECT\n",
      "        -- get year and month from date nad set it to the first day of the month\n",
      "        DATE_TRUNC('month', date) AS date,\n",
      "        dollar_fx,\n",
      "        ROW_NUMBER() OVER (PARTITION BY EXTRACT(YEAR FROM date), EXTRACT(MONTH FROM date) ORDER BY date) AS row_num\n",
      "    FROM econ.tipo_de_cambio\n",
      "), monthly_interest_rate AS (\n",
      "    SELECT\n",
      "        -- get year and month from date nad set it to the first day of the month\n",
      "        DATE_TRUNC('month', date) AS date,\n",
      "        tiie,\n",
      "        ROW_NUMBER() OVER (PARTITION BY EXTRACT(YEAR FROM date), EXTRACT(MONTH FROM date) ORDER BY date) AS row_num\n",
      "    FROM econ.tasa_de_interes\n",
      ")\n",
      "SELECT\n",
      "    i.date,\n",
      "    i.inpc,\n",
      "    fx.dollar_fx,\n",
      "    ir.tiie\n",
      "FROM econ.inflacion AS i\n",
      "LEFT JOIN monthly_fx AS fx\n",
      "    ON i.date = fx.date\n",
      "    AND fx.row_num = 1\n",
      "LEFT JOIN monthly_interest_rate AS ir\n",
      "    ON i.date = ir.date\n",
      "    AND ir.row_num = 1\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Query to join tables\n",
    "query = open('sql/ELT.sql', 'r').read()\n",
    "\n",
    "# add CREATE TABLE AS to query\n",
    "query = \"CREATE TABLE {database_name}.{table_names} AS (\\n{query_str})\".format(\n",
    "    database_name=config['aws']['database'],\n",
    "    table_names=config['aws']['elt_table_name'],\n",
    "    query_str=query\n",
    ")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Run query in athena\n",
    "response = wr.athena.read_sql_query(\n",
    "    sql=query,\n",
    "    database=config['aws']['database'],\n",
    "    ctas_approach=False, \n",
    "    boto3_session=session\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>inpc</th>\n",
       "      <th>dollar_fx</th>\n",
       "      <th>tiie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>98.794998</td>\n",
       "      <td>19.489901</td>\n",
       "      <td>7.6311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>99.171371</td>\n",
       "      <td>18.400400</td>\n",
       "      <td>7.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>99.492157</td>\n",
       "      <td>18.861000</td>\n",
       "      <td>7.8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>99.154846</td>\n",
       "      <td>18.296700</td>\n",
       "      <td>7.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>98.994080</td>\n",
       "      <td>18.787800</td>\n",
       "      <td>7.8455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>131.445007</td>\n",
       "      <td>17.930500</td>\n",
       "      <td>11.5035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>132.373001</td>\n",
       "      <td>17.214300</td>\n",
       "      <td>11.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>133.554993</td>\n",
       "      <td>16.919001</td>\n",
       "      <td>11.5035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>133.681000</td>\n",
       "      <td>17.133499</td>\n",
       "      <td>11.5012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.021700</td>\n",
       "      <td>11.4937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        inpc  dollar_fx     tiie\n",
       "0   2018-01-01   98.794998  19.489901   7.6311\n",
       "1   2018-02-01   99.171371  18.400400   7.6600\n",
       "2   2018-03-01   99.492157  18.861000   7.8294\n",
       "3   2018-04-01   99.154846  18.296700   7.8503\n",
       "4   2018-05-01   98.994080  18.787800   7.8455\n",
       "..         ...         ...        ...      ...\n",
       "70  2023-11-01  131.445007  17.930500  11.5035\n",
       "71  2023-12-01  132.373001  17.214300  11.5033\n",
       "72  2024-01-01  133.554993  16.919001  11.5035\n",
       "73  2024-02-01  133.681000  17.133499  11.5012\n",
       "74  2024-03-01         NaN  17.021700  11.4937\n",
       "\n",
       "[75 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download data\n",
    "# download data\n",
    "df_banxico_inegi = wr.athena.read_sql_query(\n",
    "    sql=f\"SELECT * FROM {config['aws']['database']}.{config['aws']['elt_table_name']}\",\n",
    "    database=config['aws']['database'],\n",
    "    ctas_approach=False, \n",
    "    boto3_session=session\n",
    ")\n",
    "\n",
    "df_banxico_inegi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arquitectura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
